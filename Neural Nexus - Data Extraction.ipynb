{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries for data crawling and scraping\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = r\"D:\\Personal Projects\\IP Data Extraction\\chromedriver.exe\"\n",
    "website_url = \"https://visort2i.github.io/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read text file and store each line as a list element\n",
    "with open(r\"D:\\College Work\\CSCI 566\\Project\\classes.txt\", \"r\") as f:\n",
    "    ip_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of all classes to be used for extracting data\n",
    "element_directory = {\"Prompt Text\": \"txt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractRequiredData(base_url, chromedriver_path, class_file_names):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing the website\n",
    "driver = webdriver.Chrome(executable_path=chromedriver_path)\n",
    "driver.get(website_url)\n",
    "\n",
    "#Maximizing the window\n",
    "driver.maximize_window()\n",
    "images_downloaded = 0\n",
    "\n",
    "while(images_downloaded < 1000):\n",
    "    #Extract the prompt text\n",
    "    prompt_text = driver.find_element_by_id(element_directory[\"Prompt Text\"]).text\n",
    "\n",
    "    # Split the text string into words and check if it exists in input_list\n",
    "    prompt_words = prompt_text.split()\n",
    "\n",
    "    # Create a directory to store the downloaded images\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "\n",
    "    # Check if any word in the word_list is present in the text string\n",
    "    if any(word in prompt_words for word in ip_list):\n",
    "        \n",
    "        # Send a GET request to the webpage and get the HTML content\n",
    "        response = requests.get(driver.current_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        images = driver.find_elements_by_css_selector('img[id^=\"m5_\"]')\n",
    "        \n",
    "        images_downloaded += len(images)\n",
    "        # Download each image file and save it in the images directory\n",
    "        for i in range(len(images)):\n",
    "            image_url = images[i].get_attribute('src')\n",
    "            response = requests.get(driver.current_url + image_url, stream=True)\n",
    "            with open('images/' + prompt_text+str(i), 'wb') as out_file:\n",
    "                out_file.write(response.content)\n",
    "\n",
    "        driver.refresh()\n",
    "\n",
    "    else:\n",
    "        driver.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = driver.find_elements_by_css_selector('img[id^=\"m5_\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://visort2i.github.io/images/stable-diffusion/22927_0.png'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].get_attribute('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<img ,=\"\" alt=\"\" height=\"256\" id=\"m5_0\" width=\"256\"/>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the prompt text\n",
    "prompt_text = driver.find_element_by_id(element_directory[\"Prompt Text\"]).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a clock above a baseball bat'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_class.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
